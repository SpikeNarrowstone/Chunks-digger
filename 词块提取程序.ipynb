{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "import string\n",
    "\n",
    "import stanfordnlp  \n",
    "\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp = StanfordCoreNLP(r'C:\\Users\\spike\\python\\stanford-corenlp-full-2018-10-05',lang='en')\n",
    "\n",
    "def fragsT(s): #定位了各类括号，找到句子中的各种结构\n",
    "    parse=nlp.parse(s) #.replace(' ','')\n",
    "    parsepos=\"\"\n",
    "    frags=[]\n",
    "    #print(parse)\n",
    "    cln=[]\n",
    "    crn=[]\n",
    "    x1=0\n",
    "    #x2=0\n",
    "    #y1=0\n",
    "    y2=0\n",
    "    x0=0\n",
    "    for n1 in range(0,len(parse)):\n",
    "        if parse[n1]=='(':\n",
    "            t=0\n",
    "            t0=0\n",
    "            while n1-t0-1>=0 and parse[n1-1-t0]==' ':\n",
    "                t0+=1\n",
    "            if parse[n1-1-t0]=='\\n' :\n",
    "                t=t0\n",
    "            else:\n",
    "                t=0\n",
    "            x1+=1\n",
    "            y1=0\n",
    "            for cha in parse[n1:]:\n",
    "                if cha==\")\":\n",
    "                    y1+=1\n",
    "            cln.append(((n1,x1-1,y1),t))\n",
    "        elif parse[n1]==\")\":\n",
    "            x2=x1\n",
    "            y2=0\n",
    "            for cha in parse[n1:]:\n",
    "                if cha==\")\":\n",
    "                    y2+=1\n",
    "            crn.append((n1,x1,y2-1))\n",
    "    #print((cln,crn))\n",
    "    #print(len(cln),len(crn))\n",
    "    for cl in cln:\n",
    "        frag=\"\"\n",
    "        n=0\n",
    "        while frag==\"\" and n<=len(crn):\n",
    "                cr=crn[n]\n",
    "                if cl[0][0]<cr[0] and  cl[0][1]-cr[2]==cr[1]-cl[0][2]:\n",
    "                    #print(((cl,cr)))\n",
    "                    frag=parse[cl[0][0]:cr[0]+1]\n",
    "                    frags.append((frag,cl[1]))\n",
    "                n+=1\n",
    "    result=[frags[0]]\n",
    "    for n in range(1,len(frags)):\n",
    "        n1=n\n",
    "        while n1>=0 and frags[n1][1]==0:\n",
    "            n1=n1-1\n",
    "        result.append((frags[n][0],frags[n1][1]))\n",
    "    return result\n",
    "\n",
    "def SPCanalyseText(text): #文本向量化 返回值[0] 短语数量、[1]短语复杂度[2]短语长度 [3]短语成分\n",
    "    sentlist=readsenttext(text)\n",
    "    sentdatas=[]\n",
    "    for s in sentlist:\n",
    "        sentdatas.append(SPCanalyse(s))  #SPCanaluse=[NP,[NP,NP,NP],['LOVE','LOVE','LOVE']]\n",
    "    print(sentdatas)\n",
    "    phrasen=0\n",
    "    dphrasen=0\n",
    "    phrasel=0\n",
    "    data=[]\n",
    "    phrasecate=[]\n",
    "    for c in sentdatas: #句子合集中的句子数据\n",
    "        for c1 in c: #句子中的短语数据合集\n",
    "            if c1[0] not in phrasecate:\n",
    "                phrasecate.append(c1[0])\n",
    "                phrasen+=1#构式类别\n",
    "           \n",
    "            phrasel+=len(c1[2])        #构式长度\n",
    "            if  c1[0]=='NP' and len(c1[1])>=1 and c1[1][0]=='NP':\n",
    "                components=[c1[1]]\n",
    "                dphrasen+=len(c1[1])  #构式复杂度\n",
    "            else:\n",
    "                components=[c1[0]]\n",
    "                components.extend(c1[1]) #构式结构\n",
    "                dphrasen+=len(c1[1])+1\n",
    "            data.append((phrasen,dphrasen,phrasel,components))\n",
    "    return data\n",
    "\n",
    "def SPCanalyse(s):  # Synergetic Phrase Components Analyse 返回列表中有成分，成分直属成分，以及成分下的词汇 \n",
    "    phcons=(\"ADJP\",\"ADVP\",\"CONJP\",\"FRAG\",\n",
    "            \"INTJ\",\"LST\",\"NAC\",\"NP\",\"NX\",\n",
    "            \"PP\",\"PRN\",\"PRT\",\"QP\",\"RRC\",\n",
    "            \"UCP\",\"VP\",\"WHADJP\",\"WHAVP\",'WHADVP',\n",
    "            \"WHNP\",\"WHPP\",\"X\")\n",
    "    postags=(\"CC\",\"CD\",\"DT\",\"EX\",\"FW\",\n",
    "             \"IN\",\"JJ\",\"JJR\",\"JJS\",\"LS\",\n",
    "             \"MD\",\"NN\",\"NNS\",\"NNP\",\"NNPS\",\n",
    "             \"PDT\",\"POS\",\"PRP\",\"PRP$\",\"RB\",\n",
    "             \"RBR\",\"RBS\",\"RP\",\"SYM\",\"TO\",\"UH\",\n",
    "             \"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBP\",\"VBZ\",\n",
    "             \"WDT\",\"WP\",\"WP$\",\"WRB\")\n",
    "    clstags=[\"S\",\"SBAR\",\"SBARQ\",\"SINV\",\"SQ\"]\n",
    "    avoidance=string.punctuation+string.whitespace\n",
    "    target=fragsT(s)\n",
    "    print(target)\n",
    "    ddphs=[]\n",
    "    for line in target:\n",
    "        line=line[0].replace('\\r\\n','').replace('(',' ( ').replace(')',' ) ')\n",
    "        line=line.split()\n",
    "        #print(line)\n",
    "        if line[1] in phcons or line[1] in clstags:\n",
    "            words=[]\n",
    "            ddph=[]\n",
    "            for n in range(2,len(line)):\n",
    "                \n",
    "                if line[n] in phcons or line[n]=='CC':\n",
    "                    x=0\n",
    "                    y=0\n",
    "                    for n1 in range(0,n):\n",
    "                        if line[n1]=='(':\n",
    "                            x+=1\n",
    "                        if line[n1]==')' or line[n1] in ('S','SBAR'):\n",
    "                            y+=1\n",
    "                    if x-y==2:# or x-y==1:\n",
    "                        #if not line[1]=='NP' and line[n]=='NP':\n",
    "                        ddph.append(line[n]) \n",
    "                #print(line[n])\n",
    "                if line[n] not in phcons and line[n] not in postags and \\\n",
    "                line[n] not in clstags and line[n] not in avoidance:# or line[n]==',':\n",
    "                    words.append(line[n])\n",
    "                if line[n] in avoidance and line[n] not in ('(',')') and line[n-1]==line[n]:\n",
    "                    words.append(line[n])\n",
    "                    print(words)\n",
    "            if line[1]=='VP' and len(line)>=3 and line[3]=='TO':      \n",
    "                ddphs.append(('TO',ddph,words))\n",
    "            else:\n",
    "                ddphs.append((line[1],ddph,words))\n",
    "            #print(ddphs)\n",
    "    return ddphs\n",
    "            \n",
    "\n",
    "def SCdigText(text,chunk_len=7): #有问题 返回值为 词典 词组：（词块长度，类型）\n",
    "    avoidance=string.punctuation+string.whitespace\n",
    "    sentlist=nltk.sent_tokenize(text)\n",
    "    sentdatas=[]\n",
    "    for s in sentlist:\n",
    "        sentdatas.append(SPCanalyse(s))\n",
    "    target={}\n",
    "    for s in sentdatas:\n",
    "        for c in s:\n",
    "            compo=''\n",
    "            for w in c[2]:\n",
    "                if w in avoidance or w in (\"'m\",\"'re\",\"n't\",\"'ll\"):\n",
    "                    compo=compo[:-1]\n",
    "                \n",
    "                compo+=w+' '\n",
    "            target[(compo[:-1])]=c[0]\n",
    "    print(target)\n",
    "    result={}\n",
    "    for n in range(0,chunk_len):\n",
    "        for chunk in target:\n",
    "            if len(chunk.split())==chunk_len-n:\n",
    "                result[chunk]=(chunk_len-n,target[chunk])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"(ROOT\\r\\n  (S\\r\\n    (S\\r\\n      (NP (PRP$ My) (NN name))\\r\\n      (VP (VBZ is)\\r\\n        (NP (NNP Adam))))\\r\\n    (CC and)\\r\\n    (S\\r\\n      (NP (PRP I))\\r\\n      (VP (VBP 'm)\\r\\n        (NP\\r\\n          (NP (DT a) (NN freshman))\\r\\n          (PP (IN at)\\r\\n            (NP (JJ senior) (JJ high) (NN school))))))\\r\\n    (. .)))\", 0), (\"(S\\r\\n    (S\\r\\n      (NP (PRP$ My) (NN name))\\r\\n      (VP (VBZ is)\\r\\n        (NP (NNP Adam))))\\r\\n    (CC and)\\r\\n    (S\\r\\n      (NP (PRP I))\\r\\n      (VP (VBP 'm)\\r\\n        (NP\\r\\n          (NP (DT a) (NN freshman))\\r\\n          (PP (IN at)\\r\\n            (NP (JJ senior) (JJ high) (NN school))))))\\r\\n    (. .))\", 2), ('(S\\r\\n      (NP (PRP$ My) (NN name))\\r\\n      (VP (VBZ is)\\r\\n        (NP (NNP Adam))))', 4), ('(NP (PRP$ My) (NN name))', 6), ('(PRP$ My)', 6), ('(NN name)', 6), ('(VP (VBZ is)\\r\\n        (NP (NNP Adam)))', 6), ('(VBZ is)', 6), ('(NP (NNP Adam))', 8), ('(NNP Adam)', 8), ('(CC and)', 4), (\"(S\\r\\n      (NP (PRP I))\\r\\n      (VP (VBP 'm)\\r\\n        (NP\\r\\n          (NP (DT a) (NN freshman))\\r\\n          (PP (IN at)\\r\\n            (NP (JJ senior) (JJ high) (NN school))))))\", 4), ('(NP (PRP I))', 6), ('(PRP I)', 6), (\"(VP (VBP 'm)\\r\\n        (NP\\r\\n          (NP (DT a) (NN freshman))\\r\\n          (PP (IN at)\\r\\n            (NP (JJ senior) (JJ high) (NN school)))))\", 6), (\"(VBP 'm)\", 6), ('(NP\\r\\n          (NP (DT a) (NN freshman))\\r\\n          (PP (IN at)\\r\\n            (NP (JJ senior) (JJ high) (NN school))))', 8), ('(NP (DT a) (NN freshman))', 10), ('(DT a)', 10), ('(NN freshman)', 10), ('(PP (IN at)\\r\\n            (NP (JJ senior) (JJ high) (NN school)))', 10), ('(IN at)', 10), ('(NP (JJ senior) (JJ high) (NN school))', 12), ('(JJ senior)', 12), ('(JJ high)', 12), ('(NN school)', 12), ('(. .)', 4)]\n",
      "['My', 'name', 'is', 'Adam', 'and', 'I', \"'m\", 'a', 'freshman', 'at', 'senior', 'high', 'school', '.']\n",
      "{\"My name is Adam and I'm a freshman at senior high school.\": 'S', 'My name is Adam': 'S', 'My name': 'NP', 'is Adam': 'VP', 'Adam': 'NP', \"I'm a freshman at senior high school\": 'S', 'I': 'NP', \"'m a freshman at senior high school\": 'VP', 'a freshman at senior high school': 'NP', 'a freshman': 'NP', 'at senior high school': 'PP', 'senior high school': 'NP'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"I'm a freshman at senior high school\": (7, 'S'),\n",
       " \"'m a freshman at senior high school\": (7, 'VP'),\n",
       " 'a freshman at senior high school': (6, 'NP'),\n",
       " 'My name is Adam': (4, 'S'),\n",
       " 'at senior high school': (4, 'PP'),\n",
       " 'senior high school': (3, 'NP'),\n",
       " 'My name': (2, 'NP'),\n",
       " 'is Adam': (2, 'VP'),\n",
       " 'a freshman': (2, 'NP'),\n",
       " 'Adam': (1, 'NP'),\n",
       " 'I': (1, 'NP')}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=\"My name is Adam and I'm a freshman at senior high school.\"\n",
    "SCdigText(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
